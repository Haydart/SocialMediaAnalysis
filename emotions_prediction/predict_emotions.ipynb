{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import twint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/r.makowiecki/PycharmProjects/SocialMediaAnalysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir = './emotions_prediction'\n",
    "print(os.getcwd())\n",
    "\n",
    "with open(\"{}/data/dataset.raw.pickle\".format(dir), \"rb\") as dataset_file:\n",
    "    dataset = pickle.load(dataset_file, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n[{'label': array([1., 0., 0., 0., 0., 0., 0.])}, {'label': array([0., 1., 0., 0., 0., 0., 0.])}, {'label': array([0., 0., 1., 0., 0., 0., 0.])}, {'label': array([0., 0., 0., 1., 0., 0., 0.])}, {'label': array([0., 0., 0., 0., 1., 0., 0.])}, {'label': array([0., 0., 0., 0., 0., 1., 0.])}, {'label': array([0., 0., 0., 0., 0., 0., 1.])}, {'label': array([1., 0., 0., 0., 0., 0., 0.])}, {'label': array([0., 1., 0., 0., 0., 0., 0.])}, {'label': array([0., 0., 1., 0., 0., 0., 0.])}]\n['During the period of falling in love, each time that we met and especially when we had not met for a long time.', 'When I was involved in a traffic accident.', 'When I was driving home after  several days of hard work, there was a motorist ahead of me who was driving at 50 km/hour and refused, despite his low speeed to let me overtake.', 'When I lost the person who meant the most to me.', \"The time I knocked a deer down - the sight of the animal's injuries and helplessness.  The realization that the animal was so badly hurt that it had to be put down, and when the animal screamed at the moment of death.\", 'When I did not speak the truth.', 'When I caused problems for somebody because he could not keep the appointed time and this led to various consequences.', 'When I got a letter offering me the Summer job that I had applied for.', 'When I was going home alone one night in Paris and a man came up behind me and asked me if I was not afraid to be out alone so late at night.', 'When I was talking to HIM at a party for the first time in a long while and a friend came and interrupted us and HE left.']\n"
     ]
    }
   ],
   "source": [
    "labels = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']\n",
    "\n",
    "# print dataset type and sample\n",
    "print(type(dataset))\n",
    "print(dataset['info'][:10])\n",
    "print(dataset['texts'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 1.]), array([1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "X = dataset['texts']\n",
    "Y = [item['label'] for item in dataset['info']]\n",
    "    \n",
    "#print labels sample\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model taken from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM. Place in appropriate directory\n",
    "model = KeyedVectors.load_word2vec_format('./emotions_prediction/model/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_english_stopwords():\n",
    "    file_path = './emotions_prediction/data/nltk_english_stopwords'\n",
    "    with open(file_path, 'r') as stop_words_file:\n",
    "        return stop_words_file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words_list = set('for a of the and to in'.split())\n",
    "\n",
    "def vectorize_sentence(model_w2v, sentence, stop_words=stop_words_list):\n",
    "    words = gensim.utils.simple_preprocess(sentence)\n",
    "\n",
    "    sentence_vector = []\n",
    "    for word in words:\n",
    "        if word not in stop_words and word in model_w2v.vocab:\n",
    "            sentence_vector.append(model_w2v[word])\n",
    "\n",
    "    sentence_vector = np.stack(sentence_vector, axis=0)\n",
    "\n",
    "    return np.mean(sentence_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When my aunt took her own life, I felt guity for not understanding that she needed support.', 'When I was house-hunting: Another person got a flat that I would have liked, too, because he heaped a floot of words on the letter.', 'When I was 4-5 years old my mother gave me some parts of a chocolate bar and ordered me to bring it to my father working outside. On my way I could not resist the temptation and ate it myself.', 'I passed an exam which I thought I had failed.', 'A friend of mine told me that my boyfriend had been with another girl this Summer.  We had been going out together for four years and we had not done so for the last three months.  I could not believe it.', 'My parents put pressure on me to buy clothes, when I would not have liked to do so.', 'When my brothers had passed all of their exams and were able to  graduate from their courses.', 'I read a book about the sexual phantasies of women; I read about a woman having sexual intercourse with a dog.', 'I heard that a former superior of mine had died, I was later at home home reading about it in the newspaper and I thought of our interaction and how it was no longer possible.  The limited scope of human life is sad.', 'When I was at a boarding school at Lusaka, the Rhodesian soldiers came to bomb a house near our school and we saw the whole scene.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 1. 0.]\n [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])\n",
    "X_train_vectorized = [vectorize_sentence(model, sentence) for sentence in X_train]\n",
    "X_test_vectorized = [vectorize_sentence(model, sentence) for sentence in X_test]\n",
    "\n",
    "y_test = np.stack(y_test, axis=0)\n",
    "print(y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
